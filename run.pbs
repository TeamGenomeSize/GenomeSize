#!/bin/bash
#PBS -N run.pbs
#PBS -l mem=16gb
#PBS -l walltime=8:59:00
#PBS -j oe

set -e						# if any error occurs, exit 1
module load python/3.8.3    # must load python 3.8 or higher
cd ${WD}

##################
## EXPAND FLAGS ##
##################
VOLUME=${OD}/${NAME}_${FILTER_LEN}_read_volume.txt
PILEUP=${OD}/${NAME}_${FILTER_LEN}_pileup.out
JOB_ID=$( echo ${PBS_JOBID} | cut -d'.' -f1 )

#################
## GENOME SIZE ##
#################
echo "[Executing ${JOB_ID} run.pbs for ${NAME},${FILTER_LEN},${METHOD}]" >> ${LOG}

START_TIME=$( date +"%T" )					# records time taken by whole pipeline
START=$( date -u -d "${START_TIME}" +"%s" )

# sleeping 0,1,2,3 or 4 seconds to reduce possibility that two processes
# end up writing to the same file at the same time
# slightly janky, but it works as far as I can tell :^)
sleep $[ ( $RANDOM % 10 ) + 1 ]s

# taking output all .txt and giving an answer
python3 genomeSize.py -od ${OD} -n ${NAME} -p ${PILEUP} -v ${VOLUME} \
-m ${METHOD} -i ${INDEL} -rc ${R_CLIPPING} -fl ${FILTER_LEN} -pid ${JOB_ID}

FINAL_TIME=$( date +"%T" )
FINAL=$(date -u -d "${FINAL_TIME}" +"%s")

echo "$( date -u -d "0 ${FINAL} sec - ${START} sec" +"%H:%M:%S" ) elapsed" >> ${LOG}

echo "[Finished executing ${JOB_ID} run.pbs for ${NAME},${FILTER_LEN},${METHOD}]" >> ${LOG}
echo "===========================================================" >> ${LOG}
