# USER DOCUMENTATION: Genome Size

Estimating genome size from long-read sequencing data. Re-engineering and extending [Richard Edward’s implementation](https://github.com/slimsuite/diploidocus). Read length filtering, insertion/deletion bias and soft clipping bias have been accounted for.
 
Pipeline launches multiple scripts to predict genome size from a BAM file of mapped long-read data and a BUSCO generated .tsv of single copy orthologs. The pipeline produces multiple size predictions, one each for each combination of assumptions. This pipeline automates the testing of each combination of assumptions to allow for an empirical method to calculate genome size. It considers technical influences from sequencing or read mapping that may distort a genome size prediction, leaving it to the researcher’s discretion and their knowledge of the biases of their data to make a final decision.
 
# USER DOCUMENTATION
 
## Getting Started
The --help flag is available to display options.

Run with `sh main.sh [optional] -od <output_dir> -nn <species> -wd <working_dir> -b <in.bam> -sco <.tsv> [optional]`.

- how to run the pipeline
- which variables need to be set

### Required Arguments
  - `-od=OUTPUT_DIRECTORY` is required. Path of the working/output directory of script
  - `-nm=NAME` is required. Root-name for files created by pipeline
  - `-wd=WORKING_DIRECTORY` is required. Path to top level of code i.e. same level as this main.sh script


### Optional Arguments
 - `-rf=REF_GENOME` is optional; path to reference genome
 - `-sco=SINGLE_COPY_ORTHOLOGS`; path to tsv of BUSCO single copy ortholog output
 - `-b=BAM` is optional; path to bam file of mapped reads
 - `t=THREADS` is optional; number of threads to run samtools computations


## Pipeline Output: $NAME_genomeSize_log.csv
A comma-separated file containing the summary of all output generated by genomeSize.py, with headers showing which assumptions were used for each calculation.
 
### Example Output (a_thaliana/ecoli)
E_coli genome size assumption/prediction
```
insert log.csv results here
```
 
Another example out
```
insert cool code here
```
 
# Troubleshooting guide
- navigating pipeline log
 
 
```
insert cool code here
```
 
 # Assumptions

## Soft Clipping
Samtools mpileup does not explicitly state how it handles soft clipping in any official documentation, as such our understanding of this behaviour and how we subsequently interpreted a soft clipping bias was constructed through examination of the source code and the ![help](https://github.com/samtools/hts-specs/issues/80) of various other users ![asking](http://seqanswers.com/forums/showthread.php?t=31770) adjacent ![questions](https://bioinformatics.stackexchange.com/questions/157/are-soft-clipped-bases-used-for-variant-calling-in-samtools-bcftools). Soft clipped residues by default are not included in read volume measurement used, therefore a switched on flag will incorporate the effect of soft clipping on read volume. Soft clipped residues are not part of alignments so they have no influence on read depth.


### Indel Bias

The insertion deletion (indel) bias was incorporated based on the assumption that sequencing technologies such as Nanopore and PacBio are not 100% accurate. Depending on the technology, there may be a technical bias towards erroneous insertions, deletions etc. A bias towards insertions means the mapped reads are larger than reality (overinflation) and conversely a bias toward deletions in the technology suggest the mapped reads are lower than reality (underestimation). 

The indel bias flag will modify the read volume estimation by analysing the underlying bias in the sequencing data. The flag can be turned on/off by setting the assumption to true/false in assumptions.txt. The indel bias ratio equals the total matches + total insertions (total read bases mapped) divided by the total matches + total deletions (the total bases in the assembly). The calculation is computed through analysis of the mapped reads’ CIGAR strings.

### Filter Length

Short reads tend to map to repeat regions less effectively as repeats may sometimes be longer than reads sequenced, resulting in repeats being collapsed. This may artificially inflate the calculated read depth. Hence this pipeline utilises long-read sequencing data. The pipeline allows the ability to filter reads below a minimum length. The pipeline has a default setting that computes genome size with three settings - filtering reads below a minimum read length of  0, 1000 and 5000 bases. Reads are filtered from both the read volume and read depth calculations.

### Read Depth (Ailin)
Taking only the coverage of bases in regions of single copy orthologs (a gene sequence contained only once in the whole genome), the probability of overcounting reads being mapped to the wrong repeated regions is reduced. However there are still varying read depths per base in these regions due to different overlapping reads. It is not immediately clear how read depth should be calculated to give the read depths observed in each base pair in the single copy orthologs. Therefore the program calculates and returns three read depths of different assumptions for further genome size calculations.

Read depth can be calculated in the following three ways:
* Mode of modes depth (abbr. mmDepth)
    * Calculation function: modeOfModes(depths) in getDepth.py
    * Input: A list of lists of reads per base per single copy ortholog region
    * Output: A single integer representing the mode of modes depth
    * Obtains the modal read depth of each single copy ortholog in the alignment and stores those values into a list. Then finds and returns the mode of the new list.
* Overall modal depth (abbr. modeDepth)
    * Calculation function: modeDepth(depths) in getDepth.py
    * Input: A list of reads per base across all single copy ortholog regions
    * Output: A single integer representing the over modal depth
    * Takes the mode of input list using the statistics.mode() function, this is the mode over all residues in the single copy orthologs
* Median of medians depth (abbr. medDepth)
    * Calculation function: medMedian(depths) in getDepth.py
    * Input: A list of lists of reads per base per single copy ortholog region
    * Output: A single integer representing the median of medians depth
    * Similar to mode of modes but instead of taking the mode, the median is taken at each step.
    * This was introduced to handle possible underestimation of read depth - as initial assumptions showed overestimation of genome size and read depth is inversely related to genome size
    * Highly experimental

# Architecture of Pipeline
![main.sh workflow](/assets/main.sh.png)


# Help Flag
Usage: ./main.sh [optional] -od <output_dir> -nn <species> -wd <working_dir> -b <in.bam> -sco <.tsv> [optional]
Mandatory:
-nm NAME      root name for files created by pipeline
-wd PATH      path to top level of code i.e. same level as this main.sh script
-od PATH      path to desired output directory (must already exist)
-sco FILE     path to tsv of BUSCO single copy ortholog output
-b FILE       path to bam file of mapped reads
Optional:
-t INT        number of threads to run samtools computations
-c                flag to specify custom generation of assumptions

# Authors
 
#### UNSW BINF6112 Team Genome Size 2020
- **Ailin Zhang**
- **Alana Huang**
- [**Chelsea Liang**](https://www.linkedin.com/in/chelsea-liang-03674b140/)
- **Sebastian Porter Zadro**
- [**Sehhaj Grewal**](https://www.linkedin.com/in/sehhajgrewal/)
